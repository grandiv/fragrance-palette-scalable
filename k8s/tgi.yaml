apiVersion: apps/v1
kind: Deployment
metadata:
  name: tgi-deployment
  labels:
    app: tgi
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tgi
  template:
    metadata:
      labels:
        app: tgi
    spec:
      containers:
        - name: tgi
          image: ghcr.io/huggingface/text-generation-inference:2.4.0
          ports:
            - containerPort: 80
          env:
            - name: MODEL_ID
              value: "meta-llama/Llama-3.2-1B"
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: app-secret
                  key: hf-token
            - name: MAX_CONCURRENT_REQUESTS
              value: "128"
            - name: MAX_BEST_OF
              value: "6"
            - name: MAX_STOP_SEQUENCES
              value: "6"
            - name: MAX_INPUT_LENGTH
              value: "4000"
            - name: MAX_TOTAL_TOKENS
              value: "4096"
          resources:
            requests:
              memory: "4Gi"
              cpu: "1000m"
            limits:
              memory: "8Gi"
              cpu: "2000m"
          livenessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 30
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: tgi-service
spec:
  selector:
    app: tgi
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
