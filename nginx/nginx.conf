    # /nginx/nginx.conf

    user nginx;
    worker_processes auto; # Adjust based on your CPU cores if needed

    error_log /var/log/nginx/error.log warn;
    pid       /var/run/nginx.pid;

    events {
        worker_connections 1024; # Max connections per worker
    }

    http {
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;

        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /var/log/nginx/access.log  main;

        sendfile        on;
        tcp_nopush      on;
        tcp_nodelay     on;
        keepalive_timeout  65;
        types_hash_max_size 2048;
        # server_tokens off; # Hide Nginx version

        # Gzip Settings
        gzip on;
        gzip_disable "msie6";
        gzip_vary on;
        gzip_proxied any;
        gzip_comp_level 6;
        gzip_buffers 16 8k;
        gzip_http_version 1.1;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript image/svg+xml;

        # Define upstreams for load balancing
        # Docker Compose's internal DNS will resolve service names to container IPs.
        # If you scale a service (e.g., backend=3), 'backend' will resolve to multiple IPs,
        # and Nginx will round-robin by default.

        upstream frontend_servers {
            # server frontend:3000; # This will resolve to all frontend container IPs
            # For more control or specific algorithms, you might list them if DNS doesn't behave as expected for specific Nginx versions/setups
            # Example if scaling frontend to 2 instances and service name is 'frontend'
            server frontend:3000;
        }

        upstream backend_api_servers {
            # server backend:3001; # This will resolve to all backend container IPs
            # least_conn; # Good for long-lived connections or varying request loads
            server backend:3001;
        }

        server {
            listen 80 default_server;
            server_name _; # Catch all

            # Frontend - Next.js App
            location / {
                proxy_pass http://frontend_servers; # Pass to the frontend service
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_cache_bypass $http_upgrade;
                proxy_read_timeout 240s; # For potentially long-polling or SSR
                proxy_connect_timeout 240s;
            }

            # Backend API
            location /api/ {
                proxy_pass http://backend_api_servers; # Pass to the backend service
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_read_timeout 240s;
                proxy_connect_timeout 240s;

                # Optional: Rate limiting for API
                # limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
                # limit_req zone=api_limit burst=20 nodelay;
            }

            # Health check endpoint for Nginx itself (optional)
            location /nginx_status {
                stub_status on;
                access_log off;
                allow 127.0.0.1; # Or your monitoring IP
                deny all;
            }
        }
    }
    